name: 'Deploy Prometheus and Grafana'
description: 'Deploy prometheus and grafana to AWS Virtual Machine (EC2).'
branding:
  icon: upload-cloud
  color: red
inputs:
  checkout:
    description: 'Specifies if this action should checkout the code'
    required: false
    default: "true"

  # AWS Configuration
  aws_access_key_id:
    description: 'AWS access key ID'
    required: true
  aws_secret_access_key:
    description: 'AWS secret access key'
    required: true
  aws_session_token:
    description: "AWS session token, if you're using temporary credentials"
    required: false
  aws_default_region:
    description: 'AWS default region'
    required: true
    default: us-east-1
  aws_resource_identifier:
    description: "Auto-generated by default so it's unique for org/repo/branch. Set to override with custom naming the unique AWS resource identifier for the deployment. Defaults to `${org}-${repo}-${branch}`."
  aws_extra_tags:
    description: 'A list of additional tags that will be included on created resources. Example: `{"key1": "value1", "key2": "value2"}`'
    required: false
    default: '{}'

  # ENV files
  env_aws_secret:
    description: 'Secret name to pull env variables from AWS Secret Manager, could be a comma separated list, read in order. Expected JSON content.'
    required: false
  env_repo:
    description: 'File containing environment variables to be used with the app'
    required: false
  env_ghs:
    description: '`.env` file to be used with the app from Github secrets'
    required: false
  env_ghv:
    description: '`.env` file to be used with the app from Github variables'
    required: false

  # EC2 Instance config
  aws_ec2_instance_type:
    description: 'The AWS EC2 instance type'
    default: t2.medium
    required: false
  aws_ec2_instance_profile:
    description: 'The AWS IAM instance profile to use for the EC2 instance. Use if you want to pass an AWS role with specific permissions granted to the instance'
    required: false
  aws_ec2_create_keypair_sm:
    description: 'Creates a Secret in AWS secret manager to store a kypair'
    default: false
    required: false
  aws_ec2_instance_vol_size:
    description: 'Root disk size for the EC2 instance'
    default: 10
    required: false
  aws_ec2_additional_tags:
    description: 'A JSON object of additional tags that will be included on created resources. Example: `{"key1": "value1", "key2": "value2"}`'
    required: false
  aws_ec2_ami_filter:
    description: 'AMI filter to use when searching for an AMI to use for the EC2 instance. Defaults to `ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*`'
    default: 'ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*'
    required: false
  infrastructure_only:
    description: 'Set to true to provision infrastructure (with Terraform) but skip the app deployment (with ansible)'
    default: "false"
    required: false

  # prometheus stack configuration
  grafana_datasource_dir:
    description: 'Path to the grafana datasource directory'
    default: observability/grafana/datasources
    required: false
  prometheus_config:
    description: 'Path to the prometheus config file'
    default: observability/prometheus/prometheus.yml
    required: false

  # Stack Management
  tf_stack_destroy:
    description: 'Set to "true" to Destroy the created AWS infrastructure for this instance'
    default: "false"
  tf_state_file_name:
    description: 'Change this to be anything you want to. Carefull to be consistent here. A missing file could trigger recreation, or stepping over destruction of non-defined objects.'
    required: false
  tf_state_file_name_append:
    description: 'Append a string to the tf-state-file. Setting this to `unique` will generate `tf-state-aws-unique`. Can co-exist with the tf_state_file_name variable. '
    required: false
  tf_state_bucket:
    description: 'AWS S3 bucket to use for Terraform state. Defaults to `${org}-${repo}-{branch}-tf-state-aws`'
    required: false
  tf_state_bucket_destroy:
    description: 'Force purge and deletion of S3 tf_state_bucket defined. Any file contained there will be destroyed. `tf_stack_destroy` must also be `true`'
    required: false

  # Domains
  aws_domain_name:
    description: "Define the root domain name for the application. e.g. bitovi.com. If empty, ELB URL will be provided."
    required: false
  aws_sub_domain:
    description: 'Define the sub-domain part of the URL. Defaults to `${org}-${repo}-{branch}`'
  aws_root_domain:
    description: 'Deploy application to root domain. Will create root and www DNS records. Domain must exist in Route53.'
    required: false
  aws_cert_arn:
    description: 'Existing certificate ARN to be used in the ELB. Use if you manage a certificate outside of this action. See https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-list.html for how to find the certificate ARN.'
    required: false
  aws_create_root_cert:
    description: 'Generates and manage the root certificate for the application to be used in the ELB.'
    required: false
  aws_create_sub_cert: 
    description: 'Generates and manage the sub-domain certificate for the application to be used in the ELB.'
    required: false
  aws_no_cert:
    description: 'Set this to true if you want not to use a certificate in the ELB.'
    default: false
    required: false

  # VPC Inputs
  aws_vpc_create:
    description: 'Define if a VPC should be created'
    required: false
  aws_vpc_name:
    description: 'Set a specific name for the VPC'
    required: false
  aws_vpc_cidr_block:
    description: 'Define Base CIDR block which is divided into subnet CIDR blocks. Defaults to 10.0.0.0/16.'
    required: false
  aws_vpc_public_subnets:
    description: 'Comma separated list of public subnets. Defaults to 10.10.110.0/24'
    required: false
  aws_vpc_private_subnets:
    description: 'Comma separated list of private subnets. If none, none will be created.'
    required: false
  aws_vpc_availability_zones:
    description: 'Comma separated list of availability zones. Defaults to `aws_default_region.'
    required: false
  aws_vpc_id:
    description: 'AWS VPC ID. Accepts `vpc-###` values.'
    required: false
  aws_vpc_subnet_id:
    description: 'Specify a Subnet to be used with the instance. If none provided, will pick one.'
    required: false
  aws_vpc_additional_tags:
    description: 'A JSON object of additional tags that will be included on created resources. Example: `{"key1": "value1", "key2": "value2"}`'
    required: false

outputs:
  vm_url:
    description: 'The URL of the generated app'
    value: ${{ steps.deploy.outputs.vm_url }}
#        CREATE_VPC: ${{ inputs.aws_create_vpc }}

runs:
  using: 'composite'
  steps:
    - name: Checkout
      if: ${{ inputs.checkout == 'true' }}
      uses: actions/checkout@v2

    - name: Invert boolean Variable
      shell: bash
      id: set-cert
      if: ${{ inputs.aws_no_cert == 'false' }}
      run: echo "enable_cert=true" >> $GITHUB_OUTPUT

    # take the grafana datasource and prometheus config and put them in the right place (root of the deployment repo)
    - name: Copy Observability Data
      if: ${{ inputs.infrastructure_only == 'false' }}
      shell: bash
      env:
        GITHUB_ACTION_PATH: ${{ github.action_path }}
      run: |
        echo "Copying Observability Data"
        
        # Copy Grafana Datasource
        echo "    Grafana Datasource - from ${{ inputs.grafana_datasource_dir }} to $GITHUB_ACTION_PATH/observability/grafana/datasources"
        ls -l "$GITHUB_WORKSPACE/${{ inputs.grafana_datasource_dir }}"
        if [ -d "$GITHUB_WORKSPACE/${{ inputs.grafana_datasource_dir }}" ]; then
            mkdir -p "$GITHUB_ACTION_PATH/observability/grafana/datasources"
            cp "$GITHUB_WORKSPACE/${{ inputs.grafana_datasource_dir }}/*" "${GITHUB_ACTION_PATH}/observability/grafana/datasources/."
        else
            echo "    Directory ${{ inputs.grafana_datasource_dir }} not found. Using defaults instead."
        fi
        
        # Copy Prometheus Config
        echo "    Prometheus Config - from ${{ inputs.prometheus_config }} to $GITHUB_ACTION_PATH/observability/prometheus"
        if [ -e "$GITHUB_WORKSPACE/${{ inputs.prometheus_config }}" ]; then
            mkdir -p "$GITHUB_ACTION_PATH/observability/prometheus"
            cp "$GITHUB_WORKSPACE/${{ inputs.prometheus_config }}" "${GITHUB_ACTION_PATH}/observability/prometheus"
        else
            echo "    File ${{ inputs.prometheus_config }} not found. Using defaults instead."
        fi

    # copy the deployment from the github action path to the github workspace
    - name: Copy Deployment Config
      if: ${{ inputs.infrastructure_only == 'false' }}
      shell: bash
      env:
        GITHUB_ACTION_PATH: ${{ github.action_path }}
        APP_SUBDIR: gha-prometheus-deployment
      run: |
        app_path=$GITHUB_WORKSPACE/$APP_SUBDIR

        echo "Copying app Repo"
        mkdir -p "$app_path"
        cp -r  $GITHUB_ACTION_PATH/. "$app_path"

        echo "removing operations dir"
        rm -rf $app_path/operations

        echo "Debugging - ls -la $app_path"
        ls -la $app_path


    - name: Deploy with BitOps
      id: deploy
      uses: bitovi/github-actions-commons@v0.0.12
      with:
        # Current repo vars
        checkout: false
        gh_action_repo: ${{ github.action_path }}
        gh_action_input_ansible: operations/deployment/ansible
        ansible_skip : ${{ inputs.infrastructure_only }}

        # AWS
        aws_access_key_id: ${{ inputs.aws_access_key_id }}
        aws_secret_access_key: ${{ inputs.aws_secret_access_key }}
        aws_session_token: ${{ inputs.aws_session_token }}
        aws_default_region: ${{ inputs.aws_default_region }}
        aws_resource_identifier: ${{ inputs.aws_resource_identifier }}
        aws_additional_tags: ${{ inputs.aws_extra_tags }}

        # Docker
        docker_install: true
        docker_cloudwatch_enable: true
        docker_cloudwatch_skip_destroy: true
        docker_repo_app_directory: gha-prometheus-deployment

        # EC2
        aws_ec2_instance_create: true
        aws_ec2_ami_filter: ${{ inputs.aws_ec2_ami_filter }}
        aws_ec2_iam_instance_profile: ${{ inputs.aws_ec2_instance_profile }}
        aws_ec2_instance_type: ${{ inputs.aws_ec2_instance_type }}
        aws_ec2_instance_public_ip: true
        aws_ec2_create_keypair_sm: ${{ inputs.aws_ec2_create_keypair_sm }}
        aws_ec2_instance_root_vol_size: ${{ inputs.aws_ec2_instance_vol_size }}
        aws_ec2_additional_tags: ${{ inputs.aws_ec2_additional_tags }}
        aws_ec2_port_list:       "9090,3000"
        
        # AWS ELB
        aws_elb_create: true
        aws_elb_listen_port:     "443,3000"
        aws_elb_app_port:        "9090,3000"
        aws_elb_healthcheck:     "TCP:9090"

        # Stack management
        tf_stack_destroy: ${{ inputs.tf_stack_destroy }}
        tf_state_file_name: ${{ inputs.tf_state_file_name }}
        tf_state_file_name_append: ${{ inputs.tf_state_file_name_append }}
        tf_state_bucket: ${{ inputs.tf_state_bucket }}
        tf_state_bucket_destroy: ${{ inputs.tf_state_bucket_destroy }}
        tf_state_bucket_provider: 'aws'

        # AWS Route53 Domains abd Certificates
        aws_r53_enable: true
        aws_r53_domain_name: ${{ inputs.aws_domain_name }}
        aws_r53_sub_domain_name: ${{ inputs.aws_sub_domain }}
        aws_r53_root_domain_deploy: ${{ inputs.aws_root_domain }}
        aws_r53_enable_cert: ${{ steps.set-cert.outputs.enable_cert }}
        aws_r53_cert_arn: ${{ inputs.aws_cert_arn }}
        aws_r53_create_root_cert: ${{ inputs.aws_create_root_cert }}
        aws_r53_create_sub_cert: ${{ inputs.aws_create_sub_cert }}

        aws_vpc_create: ${{ inputs.aws_vpc_create }}
        aws_vpc_name: ${{ inputs.aws_vpc_name }}
        aws_vpc_cidr_block: ${{ inputs.aws_vpc_cidr_block }}
        aws_vpc_public_subnets: ${{ inputs.aws_vpc_public_subnets }}
        aws_vpc_private_subnets: ${{ inputs.aws_vpc_private_subnets }}
        aws_vpc_availability_zones: ${{ inputs.aws_vpc_availability_zones }}
        aws_vpc_id: ${{ inputs.aws_vpc_id }}
        aws_vpc_subnet_id: ${{ inputs.aws_vpc_subnet_id }}
        aws_vpc_additional_tags: ${{ inputs.aws_vpc_additional_tags }}

        # ENV files
        env_aws_secret: ${{ inputs.env_aws_secret }}
        env_repo: ${{ inputs.env_repo }}
        env_ghs: ${{ inputs.env_ghs }}
        env_ghv: ${{ inputs.env_ghv }}
